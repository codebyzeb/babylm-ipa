{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare BabyLM Evaluation Pipeline Data\n",
    "\n",
    "Script to convert BabyLM evaluation data to phonemes. First, download the [evaluation data](https://osf.io/ad7qg/) used in the [BabyLM evaluation pipeline](https://github.com/codebyzeb/evaluation-pipeline-2024?tab=readme-ov-file) then run this notebook. After converting to phonemes, the data was copied into the [forked version](https://github.com/codebyzeb/evaluation-pipeline-2024?tab=readme-ov-file) of the pipeline used in the PhonemeTransformers project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PHONEMIZER_ESPEAK_LIBRARY'] = '/opt/local/lib/libespeak-ng.dylib'\n",
    "from g2p_plus import transcribe_utterances\n",
    "\n",
    "INPUT_DIR = \"evaluation_data\"\n",
    "OUTPUT_DIR = \"evaluation_data_phonemized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w ʌ t WORD_BOUNDARY ʌ WORD_BOUNDARY k ə n ʌ n d ɹ ə m WORD_BOUNDARY']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe_utterances(['what a conundrum'], backend='phonemizer', language='en-us', keep_word_boundaries=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['sentence_good', 'sentence_bad', 'sentence', 'question', 'passage', 'premise', 'hypothesis', 'sentence1', 'sentence2', 'paragraph', 'answer', 'question1', 'question2', 'text', 'span1_text', 'span2_text', 'Context1', 'Context2', 'Target1', 'Target2']\n",
    "folders = ['blimp_filtered', 'glue_filtered', 'supplement_filtered', 'ewok_filtered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------\n",
      "----------\n",
      "Phonemizing blimp_filtered\n",
      "----------\n",
      "----------\n",
      "\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/ellipsis_n_bar_2.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/principle_A_case_2.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/existential_there_quantifiers_1.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/causative.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/distractor_agreement_relative_clause.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/anaphor_number_agreement.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/wh_vs_that_no_gap.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/animate_subject_trans.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/superlative_quantifiers_1.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/determiner_noun_agreement_irregular_2.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/only_npi_scope.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/irregular_plural_subject_verb_agreement_1.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/sentential_negation_npi_scope.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/principle_A_reconstruction.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/left_branch_island_simple_question.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/passive_1.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/drop_argument.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/existential_there_quantifiers_2.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/determiner_noun_agreement_with_adj_2.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/wh_island.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/ellipsis_n_bar_1.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/principle_A_case_1.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/superlative_quantifiers_2.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/inchoative.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/wh_questions_subject_gap.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/adjunct_island.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/complex_NP_island.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/wh_vs_that_with_gap.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/irregular_plural_subject_verb_agreement_2.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/determiner_noun_agreement_irregular_1.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/expletive_it_object_raising.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/wh_questions_subject_gap_long_distance.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/coordinate_structure_constraint_complex_left_branch.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/only_npi_licensor_present.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/determiner_noun_agreement_with_adjective_1.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/passive_2.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/regular_plural_subject_verb_agreement_1.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/determiner_noun_agreement_with_adj_irregular_2.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/animate_subject_passive.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/npi_present_1.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/irregular_past_participle_adjectives.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/tough_vs_raising_1.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/sentential_negation_npi_licensor_present.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/existential_there_object_raising.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/wh_vs_that_with_gap_long_distance.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/sentential_subject_island.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/intransitive.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/principle_A_domain_3.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/principle_A_domain_1.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/determiner_noun_agreement_1.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/left_branch_island_echo_question.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/anaphor_gender_agreement.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/irregular_past_participle_verbs.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/tough_vs_raising_2.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/matrix_question_npi_licensor_present.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/npi_present_2.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/determiner_noun_agreement_with_adj_irregular_1.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/regular_plural_subject_verb_agreement_2.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/wh_vs_that_no_gap_long_distance.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/existential_there_subject_raising.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/transitive.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/distractor_agreement_relational_noun.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/principle_A_c_command.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/wh_questions_object_gap.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/coordinate_structure_constraint_object_extraction.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/principle_A_domain_2.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/blimp_filtered/determiner_noun_agreement_2.jsonl\n",
      "Done phonemizing\n",
      "\n",
      "----------\n",
      "----------\n",
      "Phonemizing glue_filtered\n",
      "----------\n",
      "----------\n",
      "\n",
      "----------------\n",
      "Phonemizing evaluation_data/glue_filtered/multirc.train.jsonl\n",
      "Failed to phonemize 3 sentences (0.01%) out of 27243 total sentences\n",
      "----------------\n",
      "Phonemizing evaluation_data/glue_filtered/sst2.valid.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/glue_filtered/rte.valid.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/glue_filtered/cola.valid.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/glue_filtered/boolq.train.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/glue_filtered/mnli.valid.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/glue_filtered/mrpc.train.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/glue_filtered/qqp.train.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/glue_filtered/qnli.train.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/glue_filtered/wsc.train.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/glue_filtered/boolq.valid.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/glue_filtered/mnli.train.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/glue_filtered/mnli-mm.valid.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/glue_filtered/mrpc.valid.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/glue_filtered/qqp.valid.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/glue_filtered/qnli.valid.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/glue_filtered/wsc.valid.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/glue_filtered/multirc.valid.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/glue_filtered/sst2.train.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/glue_filtered/mnli.subs.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/glue_filtered/rte.train.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/glue_filtered/cola.train.jsonl\n",
      "Done phonemizing\n",
      "\n",
      "----------\n",
      "----------\n",
      "Phonemizing supplement_filtered\n",
      "----------\n",
      "----------\n",
      "\n",
      "----------------\n",
      "Phonemizing evaluation_data/supplement_filtered/qa_congruence_easy.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/supplement_filtered/turn_taking.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/supplement_filtered/subject_aux_inversion.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/supplement_filtered/qa_congruence_tricky.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/supplement_filtered/hypernym.jsonl\n",
      "Done phonemizing\n",
      "\n",
      "----------\n",
      "----------\n",
      "Phonemizing ewok_filtered\n",
      "----------\n",
      "----------\n",
      "\n",
      "----------------\n",
      "Phonemizing evaluation_data/ewok_filtered/social-relations.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/ewok_filtered/physical-relations.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/ewok_filtered/agent-properties.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/ewok_filtered/physical-interactions.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/ewok_filtered/material-dynamics.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/ewok_filtered/material-properties.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/ewok_filtered/social-properties.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/ewok_filtered/social-interactions.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/ewok_filtered/quantitative-properties.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/ewok_filtered/spatial-relations.jsonl\n",
      "----------------\n",
      "Phonemizing evaluation_data/ewok_filtered/physical-dynamics.jsonl\n",
      "Done phonemizing\n"
     ]
    }
   ],
   "source": [
    "for folder in folders:\n",
    "\n",
    "    print(f\"\\n----------\\n----------\\nPhonemizing {folder}\\n----------\\n----------\\n\")\n",
    "\n",
    "    files = []\n",
    "    for root, _, filenames in os.walk(f'{INPUT_DIR}/{folder}'):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.jsonl'):\n",
    "                files.append(os.path.join(root, filename))\n",
    "\n",
    "    for file in files:\n",
    "        print(f\"----------------\\nPhonemizing {file}\")\n",
    "\n",
    "        with open(file, 'r') as f:\n",
    "            data = f.readlines()\n",
    "            data = [json.loads(line) for line in data]\n",
    "\n",
    "        data_keys = []\n",
    "        for line in data:\n",
    "            data_keys += line.keys()\n",
    "        data_keys = list(set(data_keys))\n",
    "\n",
    "        for key in keys:\n",
    "            if key in data_keys:\n",
    "                sentences = [line[key] for line in data]\n",
    "                phonemized = transcribe_utterances(sentences, backend='phonemizer', language='en-us', keep_word_boundaries=True, allow_possibly_faulty_word_boundaries=True)\n",
    "                if len(phonemized) != len(sentences):\n",
    "                    print(f\"Failed to phonemize {len(sentences) - len(phonemized)} sentences ({(len(sentences) - len(phonemized)) / len(sentences) * 100:.2f}%) out of {len(sentences)} total sentences\")\n",
    "                    continue\n",
    "                i = 0\n",
    "                for line in data:\n",
    "                    if key in line:\n",
    "                        line[key] = phonemized[i]\n",
    "                        i += 1\n",
    "\n",
    "        # Save the phonemized data\n",
    "        filename = file.split('/')[-1]\n",
    "        os.makedirs(f'{OUTPUT_DIR}/{folder}', exist_ok=True)\n",
    "        with open(f'{OUTPUT_DIR}/{folder}/{filename}', 'w', encoding='utf-8') as f:\n",
    "            for line in data:\n",
    "                f.write(json.dumps(line, ensure_ascii=False) + '\\n')\n",
    "        \n",
    "    print(\"Done phonemizing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zebulongoriely/Documents/UniDocs/PHD/research/projects/babylm-ipa/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------Counting blimp_filtered----------\n",
      "\n",
      "Counting evaluation_data/blimp_filtered/adjunct_island.jsonl\n",
      "Counting evaluation_data/blimp_filtered/anaphor_gender_agreement.jsonl\n",
      "Counting evaluation_data/blimp_filtered/anaphor_number_agreement.jsonl\n",
      "Counting evaluation_data/blimp_filtered/animate_subject_passive.jsonl\n",
      "Counting evaluation_data/blimp_filtered/animate_subject_trans.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nz/6tzh0bsj2txd1cz18gpcms_c0000gn/T/ipykernel_32421/3194724403.py:48: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame({'folder': folder, 'file': file.split('/')[-1], 'key': key, 'count': count, 'total_lines': total_lines, 'percentage': percentage, 'average_length': average_length}, index=[0])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting evaluation_data/blimp_filtered/causative.jsonl\n",
      "Counting evaluation_data/blimp_filtered/complex_NP_island.jsonl\n",
      "Counting evaluation_data/blimp_filtered/coordinate_structure_constraint_complex_left_branch.jsonl\n",
      "Counting evaluation_data/blimp_filtered/coordinate_structure_constraint_object_extraction.jsonl\n",
      "Counting evaluation_data/blimp_filtered/determiner_noun_agreement_1.jsonl\n",
      "Counting evaluation_data/blimp_filtered/determiner_noun_agreement_2.jsonl\n",
      "Counting evaluation_data/blimp_filtered/determiner_noun_agreement_irregular_1.jsonl\n",
      "Counting evaluation_data/blimp_filtered/determiner_noun_agreement_irregular_2.jsonl\n",
      "Counting evaluation_data/blimp_filtered/determiner_noun_agreement_with_adj_2.jsonl\n",
      "Counting evaluation_data/blimp_filtered/determiner_noun_agreement_with_adj_irregular_1.jsonl\n",
      "Counting evaluation_data/blimp_filtered/determiner_noun_agreement_with_adj_irregular_2.jsonl\n",
      "Counting evaluation_data/blimp_filtered/determiner_noun_agreement_with_adjective_1.jsonl\n",
      "Counting evaluation_data/blimp_filtered/distractor_agreement_relational_noun.jsonl\n",
      "Counting evaluation_data/blimp_filtered/distractor_agreement_relative_clause.jsonl\n",
      "Counting evaluation_data/blimp_filtered/drop_argument.jsonl\n",
      "Counting evaluation_data/blimp_filtered/ellipsis_n_bar_1.jsonl\n",
      "Counting evaluation_data/blimp_filtered/ellipsis_n_bar_2.jsonl\n",
      "Counting evaluation_data/blimp_filtered/existential_there_object_raising.jsonl\n",
      "Counting evaluation_data/blimp_filtered/existential_there_quantifiers_1.jsonl\n",
      "Counting evaluation_data/blimp_filtered/existential_there_quantifiers_2.jsonl\n",
      "Counting evaluation_data/blimp_filtered/existential_there_subject_raising.jsonl\n",
      "Counting evaluation_data/blimp_filtered/expletive_it_object_raising.jsonl\n",
      "Counting evaluation_data/blimp_filtered/inchoative.jsonl\n",
      "Counting evaluation_data/blimp_filtered/intransitive.jsonl\n",
      "Counting evaluation_data/blimp_filtered/irregular_past_participle_adjectives.jsonl\n",
      "Counting evaluation_data/blimp_filtered/irregular_past_participle_verbs.jsonl\n",
      "Counting evaluation_data/blimp_filtered/irregular_plural_subject_verb_agreement_1.jsonl\n",
      "Counting evaluation_data/blimp_filtered/irregular_plural_subject_verb_agreement_2.jsonl\n",
      "Counting evaluation_data/blimp_filtered/left_branch_island_echo_question.jsonl\n",
      "Counting evaluation_data/blimp_filtered/left_branch_island_simple_question.jsonl\n",
      "Counting evaluation_data/blimp_filtered/matrix_question_npi_licensor_present.jsonl\n",
      "Counting evaluation_data/blimp_filtered/npi_present_1.jsonl\n",
      "Counting evaluation_data/blimp_filtered/npi_present_2.jsonl\n",
      "Counting evaluation_data/blimp_filtered/only_npi_licensor_present.jsonl\n",
      "Counting evaluation_data/blimp_filtered/only_npi_scope.jsonl\n",
      "Counting evaluation_data/blimp_filtered/passive_1.jsonl\n",
      "Counting evaluation_data/blimp_filtered/passive_2.jsonl\n",
      "Counting evaluation_data/blimp_filtered/principle_A_c_command.jsonl\n",
      "Counting evaluation_data/blimp_filtered/principle_A_case_1.jsonl\n",
      "Counting evaluation_data/blimp_filtered/principle_A_case_2.jsonl\n",
      "Counting evaluation_data/blimp_filtered/principle_A_domain_1.jsonl\n",
      "Counting evaluation_data/blimp_filtered/principle_A_domain_2.jsonl\n",
      "Counting evaluation_data/blimp_filtered/principle_A_domain_3.jsonl\n",
      "Counting evaluation_data/blimp_filtered/principle_A_reconstruction.jsonl\n",
      "Counting evaluation_data/blimp_filtered/regular_plural_subject_verb_agreement_1.jsonl\n",
      "Counting evaluation_data/blimp_filtered/regular_plural_subject_verb_agreement_2.jsonl\n",
      "Counting evaluation_data/blimp_filtered/sentential_negation_npi_licensor_present.jsonl\n",
      "Counting evaluation_data/blimp_filtered/sentential_negation_npi_scope.jsonl\n",
      "Counting evaluation_data/blimp_filtered/sentential_subject_island.jsonl\n",
      "Counting evaluation_data/blimp_filtered/superlative_quantifiers_1.jsonl\n",
      "Counting evaluation_data/blimp_filtered/superlative_quantifiers_2.jsonl\n",
      "Counting evaluation_data/blimp_filtered/tough_vs_raising_1.jsonl\n",
      "Counting evaluation_data/blimp_filtered/tough_vs_raising_2.jsonl\n",
      "Counting evaluation_data/blimp_filtered/transitive.jsonl\n",
      "Counting evaluation_data/blimp_filtered/wh_island.jsonl\n",
      "Counting evaluation_data/blimp_filtered/wh_questions_object_gap.jsonl\n",
      "Counting evaluation_data/blimp_filtered/wh_questions_subject_gap.jsonl\n",
      "Counting evaluation_data/blimp_filtered/wh_questions_subject_gap_long_distance.jsonl\n",
      "Counting evaluation_data/blimp_filtered/wh_vs_that_no_gap.jsonl\n",
      "Counting evaluation_data/blimp_filtered/wh_vs_that_no_gap_long_distance.jsonl\n",
      "Counting evaluation_data/blimp_filtered/wh_vs_that_with_gap.jsonl\n",
      "Counting evaluation_data/blimp_filtered/wh_vs_that_with_gap_long_distance.jsonl\n",
      "Done counting\n",
      "\n",
      "----------Counting glue_filtered----------\n",
      "\n",
      "Counting evaluation_data/glue_filtered/boolq.train.jsonl\n",
      "Counting evaluation_data/glue_filtered/boolq.valid.jsonl\n",
      "Counting evaluation_data/glue_filtered/cola.train.jsonl\n",
      "Counting evaluation_data/glue_filtered/cola.valid.jsonl\n",
      "Counting evaluation_data/glue_filtered/mnli-mm.valid.jsonl\n",
      "Counting evaluation_data/glue_filtered/mnli.subs.jsonl\n",
      "Counting evaluation_data/glue_filtered/mnli.train.jsonl\n",
      "Counting evaluation_data/glue_filtered/mnli.valid.jsonl\n",
      "Counting evaluation_data/glue_filtered/mrpc.train.jsonl\n",
      "Counting evaluation_data/glue_filtered/mrpc.valid.jsonl\n",
      "Counting evaluation_data/glue_filtered/multirc.train.jsonl\n",
      "Counting evaluation_data/glue_filtered/multirc.valid.jsonl\n",
      "Counting evaluation_data/glue_filtered/qnli.train.jsonl\n",
      "Counting evaluation_data/glue_filtered/qnli.valid.jsonl\n",
      "Counting evaluation_data/glue_filtered/qqp.train.jsonl\n",
      "Counting evaluation_data/glue_filtered/qqp.valid.jsonl\n",
      "Counting evaluation_data/glue_filtered/rte.train.jsonl\n",
      "Counting evaluation_data/glue_filtered/rte.valid.jsonl\n",
      "Counting evaluation_data/glue_filtered/sst2.train.jsonl\n",
      "Counting evaluation_data/glue_filtered/sst2.valid.jsonl\n",
      "Counting evaluation_data/glue_filtered/wsc.train.jsonl\n",
      "Counting evaluation_data/glue_filtered/wsc.valid.jsonl\n",
      "Done counting\n",
      "\n",
      "----------Counting supplement_filtered----------\n",
      "\n",
      "Counting evaluation_data/supplement_filtered/hypernym.jsonl\n",
      "Counting evaluation_data/supplement_filtered/qa_congruence_easy.jsonl\n",
      "Counting evaluation_data/supplement_filtered/qa_congruence_tricky.jsonl\n",
      "Counting evaluation_data/supplement_filtered/subject_aux_inversion.jsonl\n",
      "Counting evaluation_data/supplement_filtered/turn_taking.jsonl\n",
      "Done counting\n",
      "\n",
      "----------Counting ewok_filtered----------\n",
      "\n",
      "Counting evaluation_data/ewok_filtered/agent-properties.jsonl\n",
      "Counting evaluation_data/ewok_filtered/material-dynamics.jsonl\n",
      "Counting evaluation_data/ewok_filtered/material-properties.jsonl\n",
      "Counting evaluation_data/ewok_filtered/physical-dynamics.jsonl\n",
      "Counting evaluation_data/ewok_filtered/physical-interactions.jsonl\n",
      "Counting evaluation_data/ewok_filtered/physical-relations.jsonl\n",
      "Counting evaluation_data/ewok_filtered/quantitative-properties.jsonl\n",
      "Counting evaluation_data/ewok_filtered/social-interactions.jsonl\n",
      "Counting evaluation_data/ewok_filtered/social-properties.jsonl\n",
      "Counting evaluation_data/ewok_filtered/social-relations.jsonl\n",
      "Counting evaluation_data/ewok_filtered/spatial-relations.jsonl\n",
      "Done counting\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "tokenizer_name = 'phonemetransformers/BABYLM-TOKENIZER-BPE-PHON'\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "df = pd.DataFrame(columns=['folder', 'file', 'key', 'count', 'total_lines', 'percentage', 'average_length'])\n",
    "\n",
    "for folder in folders:\n",
    "\n",
    "    print(f\"\\n----------Counting {folder}----------\\n\")\n",
    "\n",
    "    files = []\n",
    "    for root, _, filenames in os.walk(f'{INPUT_DIR}/{folder}'):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.jsonl'):\n",
    "                files.append(os.path.join(root, filename))\n",
    "\n",
    "    files = sorted(files)\n",
    "\n",
    "    for file in files:\n",
    "        print(f\"Counting {file}\")\n",
    "\n",
    "        with open(file, 'r') as f:\n",
    "            data = f.readlines()\n",
    "            data = [json.loads(line) for line in data]\n",
    "\n",
    "        data_keys = []\n",
    "        for line in data:\n",
    "            data_keys += line.keys()\n",
    "        data_keys = list(set(data_keys))\n",
    "\n",
    "        for key in keys:\n",
    "            if key in data_keys:\n",
    "                sentences = [line[key] for line in data]\n",
    "                tokenized = tokenizer(sentences, padding=False, truncation=False)\n",
    "                # Count number of lines with more than 128 tokens\n",
    "                count = 0\n",
    "                total_length = 0\n",
    "                for i in range(len(tokenized['input_ids'])):\n",
    "                    length = len(tokenized['input_ids'][i])\n",
    "                    if length > 128:\n",
    "                        count += 1\n",
    "                    total_length += length\n",
    "                total_lines = len(tokenized['input_ids'])\n",
    "                average_length = total_length / total_lines\n",
    "                percentage = count / total_lines * 100\n",
    "                df = pd.concat([df, pd.DataFrame({'folder': folder, 'file': file.split('/')[-1], 'key': key, 'count': count, 'total_lines': total_lines, 'percentage': percentage, 'average_length': average_length}, index=[0])], ignore_index=True)\n",
    "\n",
    "    print(\"Done counting\")\n",
    "\n",
    "df.to_csv('phonemized_stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
